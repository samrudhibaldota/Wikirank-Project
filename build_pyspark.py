# -*- coding: utf-8 -*-
"""Build_pyspark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cFQ4Eq-TtbcMyGbpEtfAILecBjpRVNFO
"""

from pyspark.sql import SparkSession
import json

spark = SparkSession.builder \
    .appName("WikipediaLinkGraph") \
    .getOrCreate()

# Load the JSON file as an RDD
rdd = spark.sparkContext.textFile("wiki_parsed.json")

# Parse JSON
parsed = rdd.map(lambda line: json.loads(line))

# FlatMap each article into (source, target) links
edges = parsed.flatMap(lambda row: [(row['title'], link) for link in row['links']])

# Filter out self-links
edges = edges.filter(lambda x: x[0] != x[1])

# Optional: Convert to DataFrame for easier viewing
edges_df = edges.toDF(["source", "target"])
edges_df.show(10)